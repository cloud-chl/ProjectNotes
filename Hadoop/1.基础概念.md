## 组成架构
![](https://cdn.nlark.com/yuque/0/2025/gif/29476003/1748870743161-1450282b-f27d-4133-81a8-f8befe374b71.gif)

```markdown
NameNode（nn）: 即Master，是一个主管，管理者。
  · 管理HDFS的名称空间；
  · 配置副本策略；
  · 管理数据块（Block）映射信息；

DataNode（dn）：即Slave。NameNode下达命令，DataNode执行实际的操作
  · 存储实际的数据块

Client：即客户端
  · 文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传
  · 与NameNode交互，获取文件的位置信息；
  · 与DataNode交互，读取或写入数据；
  · Client提供一些命令来管理HDFS，比如NameNode格式化；
  · Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；

SecondaryNameNode（2nn）: 并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。
  · 辅助NameNode，分担其工作量，比如定期合并Fsimage何Edits，并推送给NameNode；
  · 在紧急情况下，可辅助恢复NameNode；
```

```markdown
ResourceManager（rm）: 全局资源调度器，负责集群资源分配。
  · 处理客户端请求
  · 监控NodeManager
  · 启动或监控ApplicationMaster
  · 资源的分配与调度

NodeManager（nm）：每个节点上的代理，负责执行 ResourceManager 分配的任务
  · 管理单个节点上的资源
  · 处理来自ResourceManager的命令
  · 处理来自ApplicationMaster的命令

ApplicationMaster (am)：为每个应用程序运行一个 ApplicationMaster，负责任务调度和协调
  · 为应用程序申请资源并分配给内部的任务
  · 任务的监控与容错

Container：
  · Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等
```

## 常用端口
```markdown
hadoop3.x 
  HDFS NameNode 内部通信端口：8020/9000/9820
  HDFS NameNode 对用户的查询端口：9870
  Yarn查看任务运行情况：8088
  历史服务器：19888

hadoop2.x
  HDFS NameNode 内部通信端口：8020/9000
  HDFS NameNode 对用户的查询端口：50070
  Yarn查看任务运行情况：8088
  历史服务器：19888
```

## 配置文件
```markdown
3.x core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml workers
2.x core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml slaves
```

## 集群启动
### 单独启动
```shell
hdfs --daemon start namenode|datanode|secondarynamenode
 
hdfs --daemon stop  namenode|datanode|secondarynamenode
```

```shell
yarn --daemon start resourcemanager|nodemanager
 
yarn --daemon stop  resourcemanager|nodemanager
```

```bash
mapred --daemon stop historyserver

mapred --daemon start historyserver
```

### 一键启动
```shell
start-dfs.sh

stop-dfs.sh
```

```shell
start-yarn.sh

stop-yarn.sh
```

```shell
start-all.sh

stop-all.sh
```

### 集群启动管理脚本
```shell
#!/bin/bash

if [ $# -lt 1 ];then
  echo "No Args Input..."
  exit;
fi

case $1 in
    "start")
        echo " ============== 启动 Hadoop集群 =============="

        echo "-------------- 启动 hdfs "--------------"
        ssh hadoop01 "/opt/hdoop/sbin/start-dfs.sh"
        echo "-------------- 启动 yarn "--------------"
        ssh hadoop02 "/opt/hdoop/sbin/start-yarn.sh"
        echo "-------------- 启动 historyserver "--------------"
        ssh hadoop01 "/opt/hdoop/bin/mapred --daemon start historyserver.sh"
        ;;
    "stop")
        echo " ============== 关闭 Hadoop集群 =============="

        echo "-------------- 关闭 historyserver "--------------"
        ssh hadoop01 "/opt/hdoop/bin/mapred --daemon stop historyserver.sh"
        echo "-------------- 关闭 yarn "--------------"
        ssh hadoop02 "/opt/hdoop/sbin/stop-yarn.sh"
        echo "-------------- 关闭 hdfs "--------------"
        ssh hadoop01 "/opt/hdoop/sbin/stop-dfs.sh"
        ;;
    *)
        echo "Input Args Error..."
esac
```

```shell
#!/bin/bash

for host in hadoop01 hadoop02 hadoop03 
do
    echo "=============== $host "==============="
    ssh $host jps
done
```

## 文件管理
### 创建文件
```shell
hadoop fs -mkdir /test1
```

### 上传下载文件
```shell
hadoop fs -put OpenJDK8U-jdk_x64_linux_hotspot_8u352b08.tar.gz /test1
hadoop fs -get OpenJDK8U-jdk_x64_linux_hotspot_8u352b08.tar.gz ./
```

### 查看文件
```shell
hadoop fs -ls /
```

## 
